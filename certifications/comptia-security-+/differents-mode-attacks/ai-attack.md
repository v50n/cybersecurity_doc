# AI Attack

## Poisoning the training data

Example: Microsoft AI chatter bot named TAY (Thinking about you)

It was created to lean by interacting with Twitter user. But Microsoft didn't program in anti-offensive behavior, so the bot became quickly racist, sexist ..

## Evasion attacks

Attackers can learn about the way AI works ==> They will change the approach and bypass de control

In plus the AI learned in the real-world information can train with the sensitive data => The attackers can try to get these data.&#x20;

